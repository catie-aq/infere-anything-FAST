Scripts to infere with any .onnx model FAST !

(if needded, TensorRT installation in a secure way via doctrt with the trtexec tool (to intall if needed!) with the command :
trtexec --onnx=your_model.onnx --saveEngine=7_classes_fp16.trt --fp16

Then run (and/or adapt the tensort.py script.
